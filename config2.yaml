model:
  d_fft: 1024
  d_model: 512
  dropout: 0.1
  heads: 4
  layers: 6
  type: transformer
paths:
  checkpoint_dir: checkpoints
  data_dir: datasets
preprocessing:
  char_repeats: 3
  languages:
  - ne
  - en_us
  lowercase: true
  n_val: 5000
  phoneme_symbols:
  - i
  - u
  - e
  - o
  - ax
  - aa
  - in
  - en
  - un
  - axn
  - aan
  - ew
  - oj
  - ow
  - axj
  - axw
  - aaj
  - aaw
  - ewn
  - ojn
  - own
  - axjn
  - axwn
  - aajn
  - aawn
  - p
  - b
  - t
  - d
  - ts
  - jh
  - tt
  - dd
  - k
  - g
  - ph
  - bh
  - th
  - dh
  - tsh
  - jhh
  - tth
  - ddh
  - kh
  - gh
  - m
  - n
  - ng
  - s
  - h
  - y
  - r
  - l
  - w
  - nn
  - sil
  - pau
  text_symbols: "a\u0901\u0902\u0903\u0905\u0906\u0907\u0908\u0909\u090A\u090B\u090C\u0910\u0913\u0914\u0915\u0916\
    \u0917\u0918\u0919\u091A\u091B\u091C\u091D\u091E\u091F\u0920\u0921\u0922\u0923\u0924\u0925\
    \u0926\u0927\u0928\u092A\u092B\u092C\u092D\u092E\u092F\u0930\u0932\u0935\u0936\u0937\u0938\
    \u0939\u093E\u093F\u0940\u0941\u0942\u0943\u0944\u0947\u0948\u094BC\u094D\u0950\u0951\u0952\
    \u0953\u0954\u0960\u0964\u0966\u0967\u0968\u0969\u096A\u096B\u096C\u096D\u096E\u096F\u0970\
    \u0971"
training:
  batch_size: 32
  batch_size_val: 32
  checkpoint_steps: 100000
  epochs: 10
  generate_steps: 500
  learning_rate: 0.0001
  n_generate_samples: 10
  scheduler_plateau_factor: 0.5
  scheduler_plateau_patience: 10
  store_phoneme_dict_in_model: true
  validate_steps: 500
  warmup_steps: 100
